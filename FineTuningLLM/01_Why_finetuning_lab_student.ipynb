{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMGxBP-yQoCl"
   },
   "source": [
    "# Compare finetuned vs. non-finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lamini\n",
    "\n",
    "lamini.api_url = os.getenv(\"POWERML__PRODUCTION__URL\")\n",
    "lamini.api_key = os.getenv(\"POWERML__PRODUCTION__KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "height": 30,
    "id": "PKnPPEyPR3MO"
   },
   "outputs": [],
   "source": [
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Non-Finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to finetuned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: This section of the notebook has been updated.\n",
    "\n",
    "When run with the query:\n",
    "\n",
    "```Tell me how to train my dog to sit```\n",
    "\n",
    "ChatGPT responds with:\n",
    "\n",
    "> Training your dog to sit is a basic and essential command that can be taught using positive reinforcement. Here's a simple step-by-step guide:\n",
    "> 1. **Prepare Treats:**\n",
    "   Gather small, soft treats that your dog enjoys. Make sure they are easy to chew and won't take too long to eat.\n",
    "> 2. **Find a Quiet Space:**\n",
    "   Choose a quiet area with minimal distractions for the training session. This will help your dog focus better.\n",
    "> 3. **Get Your Dog's Attention:**\n",
    "   Call your dog's name to get their attention. Make sure they are looking at you.\n",
    "> 4. **Use a Treat to Lure:**\n",
    "   Hold a treat close to your dog's nose, and slowly move your hand upward and slightly backward over their head. As you do this, your dog's natural response will be to follow the treat with their nose, causing them to sit.\n",
    "> 5. **Say the Command:**\n",
    "   As your dog starts to sit, say the command \"Sit\" in a clear and firm voice. Use the word consistently every time you want your dog to sit.\n",
    "> 6. **Reward and Praise:**\n",
    "   As soon as your dog sits, immediately reward them with the treat and offer verbal praise. This positive reinforcement will help them associate sitting with positive outcomes.\n",
    "> 7. **Repeat and Practice:**\n",
    "   Repeat the process several times in a row during each training session. Keep the sessions short (around 5-10 minutes) to prevent your dog from losing interest.\n",
    "> 8. **Add Duration:**\n",
    "   Once your dog consistently sits on command, you can gradually increase the duration by waiting a couple of seconds before giving the treat. This helps reinforce the sit command.\n",
    "> 9. **Generalize the Command:**\n",
    "   Practice the \"sit\" command in different locations and with various distractions to help your dog generalize the behavior.\n",
    "> 10. **Be Patient and Consistent:**\n",
    "    Patience and consistency are key in dog training. Always use positive reinforcement, and avoid punishment. If your dog doesn't succeed initially, go back a step and try again.\n",
    "> \n",
    "> Remember that each dog is unique, and some may learn more quickly than others. Adjust your training approach based on your dog's individual needs and progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama\n",
      "  Downloading llama-0.1.1.tar.gz (387 kB)\n",
      "     ---------------------------------------- 0.0/388.0 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/388.0 kB ? eta -:--:--\n",
      "     --------------- ---------------------- 153.6/388.0 kB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 388.0/388.0 kB 3.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [7 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\rmura\\AppData\\Local\\Temp\\pip-install-0q5oybyj\\llama_88432144eb204e858ee1688979e77162\\setup.py\", line 6, in <module>\n",
      "          execfile('llama/version.py')\n",
      "          ^^^^^^^^\n",
      "      NameError: name 'execfile' is not defined\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lamini\n",
      "  Downloading lamini-2.5.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lamini-configuration[yaml] (from lamini)\n",
      "  Downloading lamini_configuration-0.8.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (4.66.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (1.24.3)\n",
      "Collecting jsonlines (from lamini)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (2.0.3)\n",
      "Collecting azure-storage-blob (from lamini)\n",
      "  Downloading azure_storage_blob-12.20.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (1.2.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (3.8.5)\n",
      "Collecting faiss-cpu (from lamini)\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini) (68.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from aiohttp->lamini) (1.2.0)\n",
      "Collecting azure-core>=1.28.0 (from azure-storage-blob->lamini)\n",
      "  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from azure-storage-blob->lamini) (41.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from azure-storage-blob->lamini) (4.11.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from azure-storage-blob->lamini) (0.6.1)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from pandas->lamini) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from pandas->lamini) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from pandas->lamini) (2023.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests->lamini) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests->lamini) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests->lamini) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from scikit-learn->lamini) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from scikit-learn->lamini) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from scikit-learn->lamini) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from tqdm->lamini) (0.4.4)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.21)\n",
      "Downloading lamini-2.5.2-py3-none-any.whl (691 kB)\n",
      "   ---------------------------------------- 0.0/691.3 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 450.6/691.3 kB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 691.3/691.3 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading azure_storage_blob-12.20.0-py3-none-any.whl (392 kB)\n",
      "   ---------------------------------------- 0.0/392.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 392.2/392.2 kB 12.3 MB/s eta 0:00:00\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/14.5 MB 5.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.0/14.5 MB 8.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 10.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.9/14.5 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 13.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.3/14.5 MB 13.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.9/14.5 MB 13.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.6/14.5 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.9/14.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.9/14.5 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.5/14.5 MB 12.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.6/14.5 MB 13.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.9/14.5 MB 14.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.2/14.5 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.5 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 194.3/194.3 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: lamini-configuration, jsonlines, faiss-cpu, azure-core, azure-storage-blob, lamini\n",
      "Successfully installed azure-core-1.30.2 azure-storage-blob-12.20.0 faiss-cpu-1.8.0 jsonlines-4.0.0 lamini-2.5.2 lamini-configuration-0.8.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lamini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - English Language & Grammar Stack Exchange\n",
      "Lamini vs Llama: What's the Difference?\n",
      "Lamini and llama are two words that are often confused with each other due to their similar spellings and pronunciations. However, they have distinct meanings and origins.\n",
      "Lamini:\n",
      "Lamini is a noun that refers to a type of fish, specifically a species of mullet (Mugil cephalus). It is also known as the grey mullet or the European sea mullet. Lamini are found in the Mediterranean Sea and the Atlantic Ocean, and are prized for their flavorful flesh.\n",
      "Llama:\n",
      "Llama, on the other hand, is a noun that refers to a domesticated mammal that belongs to the camelid family. It is native to South America and is known for its soft wool, gentle disposition, and ability to carry heavy loads. Llamas are often used as pack animals, and are also kept as pets or for their wool.\n",
      "\n",
      "Key differences:\n",
      "\n",
      "* Lamini refers to a type of fish, while llama refers to a type of mammal.\n",
      "* Lamini is a scientific name for a species of fish, while llama is a common name for a domesticated mammal.\n",
      "* Lamini is not a commonly used term in everyday language, while llama is a well-known and widely used term.\n",
      "\n",
      "In summary, while lamini and llama may look and sound similar, they are two distinct words with different meanings and origins. Lamini refers to a type of fish, while llama refers to a type of mammal. It's essential to use the correct term in the appropriate context to avoid confusion.\n"
     ]
    }
   ],
   "source": [
    "import lamini\n",
    "lamini.api_key = \"7e7be4df3b18936c38709a03b869b297e074cc0349511558fb2858f0a96335d5\"\n",
    "\n",
    "llm = lamini.Lamini(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "print(llm.generate(\"what is difference between lamini vs llama?\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
